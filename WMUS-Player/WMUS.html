<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Web Audio Sequencer</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.1/jszip.min.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        :root {
            --bg-main: #121212;
            --bg-container: #1E1E1E;
            --bg-track: #2A2A2A;
            --bg-element: #404040;
            --bg-element-hover: #555555;
            --text-primary: #E0E0E0;
            --text-secondary: #A0A0A0;
            --border-color: #383838;
            --accent-cyan: #22D3EE;
            --accent-cyan-glow: rgba(34, 211, 238, 0.3);
            --accent-amber: #FBBF24;
        }

        body {
            font-family: 'Inter', sans-serif;
            -webkit-font-smoothing: antialiased;
            -moz-osx-font-smoothing: grayscale;
            background-color: var(--bg-main);
            color: var(--text-primary);
        }
        
        /* Main container */
        .main-container {
            background-color: var(--bg-container);
            border: 1px solid var(--border-color);
        }

        /* Scrollbar */
        .scroll-container::-webkit-scrollbar { height: 8px; width: 8px; }
        .scroll-container::-webkit-scrollbar-track { background: var(--bg-container); border-radius: 4px; }
        .scroll-container::-webkit-scrollbar-thumb { background: var(--bg-element); border-radius: 4px; }
        .scroll-container::-webkit-scrollbar-thumb:hover { background: var(--bg-element-hover); }

        /* Buttons */
        .btn {
            display: inline-flex;
            align-items: center;
            justify-content: center;
            padding: 0.5rem 1rem;
            border-radius: 6px;
            font-weight: 500;
            transition: all 0.2s ease-in-out;
            border: 1px solid transparent;
        }
        .btn-primary {
            background-color: var(--accent-cyan);
            color: var(--bg-main);
            box-shadow: 0 2px 10px rgba(34, 211, 238, 0.2);
        }
        .btn-primary:hover {
            filter: brightness(1.1);
        }
        .btn-secondary {
            background-color: var(--bg-element);
            border-color: var(--border-color);
        }
        .btn-secondary:hover {
            background-color: var(--bg-element-hover);
            border-color: #606060;
        }
        .btn-ghost {
            background-color: transparent;
        }
        .btn-ghost:hover {
            background-color: var(--bg-element);
        }
        .btn.active {
            background-color: var(--accent-cyan);
            color: var(--bg-main);
            border-color: var(--accent-cyan);
        }


        /* Controls */
        .custom-slider { -webkit-appearance: none; appearance: none; width: 100%; height: 4px; background: var(--bg-element); border-radius: 2px; outline: none; }
        .custom-slider::-webkit-slider-thumb { -webkit-appearance: none; appearance: none; width: 16px; height: 16px; background: var(--text-primary); border-radius: 50%; cursor: pointer; border: 2px solid var(--bg-container); }
        .custom-slider::-moz-range-thumb { width: 16px; height: 16px; background: var(--text-primary); border-radius: 50%; cursor: pointer; border: 2px solid var(--bg-container); }
        
        .custom-select {
            -webkit-appearance: none; appearance: none;
            background-color: var(--bg-element);
            border: 1px solid var(--border-color);
            border-radius: 6px;
            padding: 0.25rem 2rem 0.25rem 0.5rem;
            background-image: url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' fill='none' viewBox='0 0 20 20'%3e%3cpath stroke='%23A0A0A0' stroke-linecap='round' stroke-linejoin='round' stroke-width='1.5' d='M6 8l4 4 4-4'/%3e%3c/svg%3e");
            background-position: right 0.5rem center;
            background-repeat: no-repeat;
            background-size: 1.5em 1.5em;
        }

        /* Sequencer Elements */
        .step-button, .arranger-step {
            transition: all 0.1s ease-in-out;
            border-radius: 4px;
            position: relative;
            overflow: hidden;
            cursor: pointer;
            -webkit-user-select: none; user-select: none;
            background-color: var(--bg-element);
            box-shadow: inset 0 1px 2px rgba(0,0,0,0.3);
        }
        .step-button { width: 100%; height: 32px; }
        .step-button.beat-marker { background-color: #52525B; } /* Enhanced visibility for beat markers */
        
        .step-button.active {
            background-color: var(--accent-cyan);
            box-shadow: 0 0 12px var(--accent-cyan-glow);
        }
        .step-button.beat-marker.active { filter: brightness(0.9); }

        .playing {
             outline: 2px solid var(--accent-cyan);
             outline-offset: 2px;
             box-shadow: 0 0 12px var(--accent-cyan-glow) !important;
        }

        .indicator {
            position: absolute; bottom: 0; width: 50%; pointer-events: none; transition: height 0.05s linear, filter 0.1s ease-in-out;
            background-blend-mode: overlay;
        }
        .gain-indicator { left: 0; background-color: var(--accent-amber); opacity: 0.6; }
        .pitch-indicator { right: 0; background-color: var(--accent-cyan); opacity: 0.6; }
        
        /* Enhance indicator visibility on active steps. */
        .step-button.active .indicator {
            filter: brightness(1.5);
            opacity: 0.8;
        }

        .arranger-step, .add-arrangement-btn {
            width: 60px; height: 40px; display: flex; align-items: center; justify-content: center;
            font-size: 14px; font-weight: 500; border: 1px solid var(--border-color);
        }
        .arranger-step:not(:empty) {
            background-color: var(--accent-cyan);
            color: var(--bg-main);
            border-color: transparent;
            filter: saturate(0.5);
        }
        .add-arrangement-btn {
            font-size: 20px;
            color: var(--text-secondary);
        }

        .pattern-btn.selected {
            background-color: var(--accent-cyan);
            color: var(--bg-main);
            transform: scale(1.05);
        }
        
        .spinner {
            border: 2px solid var(--bg-element); border-top: 2px solid var(--accent-cyan);
            border-radius: 50%; width: 16px; height: 16px; animation: spin 1s linear infinite;
        }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }
    </style>
</head>
<body class="bg-gray-800/50">

    <!-- Modal Container -->
    <div class="fixed inset-0 flex items-center justify-center p-4">
        <div class="w-full max-w-7xl h-full max-h-[95vh] main-container rounded-xl shadow-2xl p-4 flex flex-col">
            <!-- Header & Global Controls -->
            <header class="flex-shrink-0 flex flex-col sm:flex-row justify-between items-center pb-4 border-b border-gray-700">
                <h1 class="text-2xl sm:text-3xl font-bold text-white mb-4 sm:mb-0">Web Sequencer</h1>
                <div class="flex items-center space-x-6">
                    <div class="flex flex-col items-center">
                        <label class="text-xs font-medium text-gray-400 mb-1">Tempo</label>
                        <div class="flex items-center space-x-2">
                             <button id="metronome-toggle-btn" class="btn btn-secondary p-2" title="Toggle Metronome">
                                 <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 12H3M21 12h-9m-9 0a9 9 0 0 0 18 0a9 9 0 0 0-18 0Z"/></svg>
                             </button>
                            <input type="range" id="tempo" min="40" max="240" value="120" class="w-24 sm:w-32 custom-slider">
                            <span id="tempo-value" class="font-mono text-base sm:text-lg w-12 text-center text-gray-300">120</span>
                        </div>
                    </div>
                    <div class="flex items-center space-x-2">
                        <button id="loop-toggle-btn" class="btn btn-secondary p-2 active" title="Toggle Loop">
                            <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12a9 9 0 1 1-6.219-8.56"/></svg>
                        </button>
                        <button id="play-stop-btn" class="btn btn-primary px-4 py-2 sm:px-6 sm:py-3 text-sm sm:text-base">
                            Play
                        </button>
                    </div>
                </div>
            </header>

            <!-- Song Arrangement Section -->
            <section class="flex-shrink-0 pt-4">
                <h2 class="text-sm font-semibold text-gray-400 mb-2">Song Arrangement</h2>
                <div id="arrangement-container" class="scroll-container flex space-x-1 overflow-x-auto pb-2 items-center"></div>
            </section>

            <!-- Sequencer Tracks -->
            <main id="sequencer-tracks" class="flex-grow flex space-x-3 overflow-x-auto py-4 border-t border-b border-gray-700/50 my-2">
            </main>

            <div class="flex-shrink-0 flex flex-col sm:flex-row justify-between items-center pt-4 border-t border-gray-700">
                <div class="flex items-center space-x-2">
                    <button id="add-track-btn" class="btn btn-secondary text-sm">
                        + Add Track
                    </button>
                </div>

                <!-- Pattern Management -->
                <div class="flex items-center space-x-2 my-4 sm:my-0">
                    <span class="text-sm font-semibold text-gray-400">Patterns:</span>
                    <div id="pattern-list" class="flex items-center space-x-1"></div>
                    <button id="add-pattern-btn" class="btn btn-secondary px-2 py-1 text-xs font-bold">+</button>
                    <button id="dup-pattern-btn" class="btn btn-ghost px-2 py-1 text-xs">Dup</button>
                </div>

                <!-- Save/Load Buttons -->
                <div class="flex space-x-2">
                    <button id="save-project-btn" class="btn btn-secondary text-sm">Save Project</button>
                    <button id="load-project-btn" class="btn btn-secondary text-sm">Load Project</button>
                    <input type="file" id="load-project-input" class="hidden" accept=".wmus">
                </div>
            </div>
        </div>
    </div>
    
    <!-- Track Template -->
    <template id="track-template">
        <div class="track p-2 rounded-lg flex flex-col space-y-3 w-40 flex-shrink-0" style="background-color: var(--bg-track);">
            <div class="track-controls w-full flex flex-col space-y-2">
                <div class="relative w-full">
                    <input type="file" class="hidden file-input" accept="audio/*">
                    <button class="w-full text-left p-2 text-xs sm:text-sm rounded-md truncate btn btn-secondary load-sound-btn">Load Sound</button>
                </div>
                <div class="flex items-center justify-between w-full">
                    <div class="flex items-center space-x-1">
                        <label class="text-xs sm:text-sm text-gray-400">Div:</label>
                        <select class="division-select custom-select text-xs sm:text-sm">
                            <option value="8">1/8</option>
                            <option value="16" selected>1/16</option>
                            <option value="32">1/32</option>
                        </select>
                    </div>
                     <button class="remove-track-btn text-gray-500 hover:text-red-400 font-bold text-lg sm:text-xl px-1">&times;</button>
                </div>
                <div class="flex items-center justify-between w-full text-xs text-gray-400">
                    <label>Swing</label>
                    <span class="swing-value font-mono">50%</span>
                </div>
                <input type="range" min="50" max="75" value="50" class="swing-slider custom-slider w-full">
            </div>
            <div class="steps-container flex-grow flex flex-col gap-1"></div>
        </div>
    </template>


    <script>
        // --- PREAMBLE ---

        class OpusEncoder {
            constructor() {
                this.isSupported = window.AudioEncoder && typeof AudioEncoder.isConfigSupported === 'function';
            }
            async encode(audioBuffer, options = { bitrate: 32000 }) {
                const config = {
                    codec: 'opus',
                    sampleRate: audioBuffer.sampleRate,
                    numberOfChannels: 1,
                    bitrate: options.bitrate,
                    bitrateMode: 'variable', 
                    opus: {
                        complexity: 10,
                        frameDuration: 20000,
                    }
                };
                if (!this.isSupported || !(await AudioEncoder.isConfigSupported(config))) {
                    return Promise.reject(new Error("Opus encoding is not supported in this browser."));
                }
                return new Promise((resolve, reject) => {
                    const encodedChunks = [];
                    const packetSizes = [];
                    const encoder = new AudioEncoder({
                        output: chunk => {
                            const chunkData = new Uint8Array(chunk.byteLength);
                            chunk.copyTo(chunkData);
                            encodedChunks.push(chunkData);
                            packetSizes.push(chunk.byteLength);
                        },
                        error: e => reject(e),
                    });
                    encoder.configure(config);
                    const pcmData = audioBuffer.getChannelData(0);
                    const sampleRate = audioBuffer.sampleRate;
                    let currentTime = 0;
                    const frameDuration = 0.02;
                    const samplesPerFrame = sampleRate * frameDuration;
                    for (let i = 0; i < pcmData.length; i += samplesPerFrame) {
                        const frameData = pcmData.subarray(i, i + samplesPerFrame);
                        if (frameData.length === 0) continue;
                        const audioData = new AudioData({
                            format: 'f32-planar', sampleRate,
                            numberOfFrames: frameData.length, numberOfChannels: 1,
                            timestamp: currentTime * 1e6, data: frameData,
                        });
                        encoder.encode(audioData);
                        currentTime += frameDuration;
                    }
                    encoder.flush().then(() => resolve({
                        blob: new Blob(encodedChunks, { type: 'audio/opus' }),
                        packetSizes: packetSizes
                    })).catch(reject);
                });
            }
        }
        
        class OpusDecoder {
            constructor() {
                this.isSupported = window.AudioDecoder && typeof AudioDecoder.isConfigSupported === 'function';
            }
            async decode(blob, sampleRate, packetSizes) {
                const config = {
                    codec: 'opus',
                    sampleRate: sampleRate,
                    numberOfChannels: 1,
                };
                if (!this.isSupported || !(await AudioDecoder.isConfigSupported(config))) {
                     console.error("Opus decoding is not supported, but an opus file was provided.");
                     return new Float32Array(0);
                }
                return new Promise(async (resolve, reject) => {
                    const decodedFrames = [];
                    let totalFrames = 0;
                    const decoder = new AudioDecoder({
                        output: audioData => {
                            const planarData = new Float32Array(audioData.numberOfFrames);
                            audioData.copyTo(planarData, { planeIndex: 0 });
                            decodedFrames.push(planarData);
                            totalFrames += audioData.numberOfFrames;
                            audioData.close();
                        },
                        error: e => reject(e),
                    });
                    decoder.configure(config);
                    
                    try {
                        const buffer = await blob.arrayBuffer();
                        let offset = 0;
                        for (const packetSize of packetSizes) {
                            if (offset + packetSize > buffer.byteLength) {
                                console.error("Packet size map exceeds buffer length.");
                                break;
                            }
                            const packetData = buffer.slice(offset, offset + packetSize);
                            const chunk = new EncodedAudioChunk({
                                type: 'key',
                                timestamp: 0,
                                data: packetData
                            });
                            decoder.decode(chunk);
                            offset += packetSize;
                        }

                        await decoder.flush();
                        
                        const pcmData = new Float32Array(totalFrames);
                        let pcmOffset = 0;
                        for (const frame of decodedFrames) {
                            pcmData.set(frame, pcmOffset);
                            pcmOffset += frame.length;
                        }
                        resolve(pcmData);
                    } catch (e) {
                        reject(e);
                    }
                });
            }
        }

        const opusEncoder = new OpusEncoder();
        const opusDecoder = new OpusDecoder();

        document.addEventListener('DOMContentLoaded', () => {
            let audioContext;
            let sequencerNode;
            let isPlaying = false;
            let isLooping = true;
            let isMetronomeOn = false;
            let tempo = 120;
            let patterns = [];
            let currentPatternId = null;
            let patternIdCounter = 0;
            let arrangement = [];
            const TARGET_SAMPLE_RATE = 44100;
            
            const gainToDbLut = new Float32Array(101);
            const MIN_DB = -60.0;
            for (let i = 0; i < 101; i++) {
                const gain = Math.pow(i / 100, 2);
                const db = gain > 0 ? 20 * Math.log10(gain) : MIN_DB;
                gainToDbLut[i] = Math.max(MIN_DB, db);
            }

            const dom = {
                playStopBtn: document.getElementById('play-stop-btn'),
                loopToggleBtn: document.getElementById('loop-toggle-btn'),
                metronomeToggleBtn: document.getElementById('metronome-toggle-btn'),
                tempoSlider: document.getElementById('tempo'),
                tempoValue: document.getElementById('tempo-value'),
                addTrackBtn: document.getElementById('add-track-btn'),
                sequencerTracks: document.getElementById('sequencer-tracks'),
                trackTemplate: document.getElementById('track-template'),
                arrangementContainer: document.getElementById('arrangement-container'),
                patternList: document.getElementById('pattern-list'),
                addPatternBtn: document.getElementById('add-pattern-btn'),
                dupPatternBtn: document.getElementById('dup-pattern-btn'),
                saveProjectBtn: document.getElementById('save-project-btn'),
                loadProjectBtn: document.getElementById('load-project-btn'),
                loadProjectInput: document.getElementById('load-project-input'),
            };
            
            const sequencerWorkletCode = `
                class SequencerProcessor extends AudioWorkletProcessor {
                    constructor() {
                        super();
                        this.isPlaying = false; this.tempo = 120; this.stepDuration = 0;
                        this.nextStepTime = 0; this.currentStep = 0;
                        this.port.onmessage = this.handleMessage.bind(this);
                        this._updateStepDuration();
                    }
                    handleMessage(event) {
                        const { type, value } = event.data;
                        if (type === 'start') { this.isPlaying = true; this.currentStep = 0; this.nextStepTime = currentTime; }
                        else if (type === 'stop') { this.isPlaying = false; }
                        else if (type === 'setTempo') { this.tempo = value; this._updateStepDuration(); }
                    }
                    _updateStepDuration() { this.stepDuration = (60.0 / this.tempo) / 8; }
                    process(inputs, outputs, parameters) {
                        if (!this.isPlaying) return true;
                        while (this.nextStepTime < currentTime + 0.1) {
                            this.port.postMessage({ type: 'tick', step: this.currentStep });
                            this.nextStepTime += this.stepDuration;
                            this.currentStep++;
                        }
                        return true;
                    }
                }
                registerProcessor('sequencer-processor', SequencerProcessor);
            `;

            async function initAudio() {
                if (!audioContext) {
                    try {
                         audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: TARGET_SAMPLE_RATE });
                         console.log(`[INIT] AudioContext initialized. Requested ${TARGET_SAMPLE_RATE}Hz, actual rate is ${audioContext.sampleRate}Hz.`);
                    } catch(e) {
                         console.warn(`[INIT] Could not create AudioContext with target sample rate. Falling back to default.`);
                         audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    }
                   
                    if (audioContext.state === 'suspended') await audioContext.resume();
                    const blob = new Blob([sequencerWorkletCode.trim()], { type: 'application/javascript' });
                    const url = URL.createObjectURL(blob);
                    await audioContext.audioWorklet.addModule(url);
                    sequencerNode = new AudioWorkletNode(audioContext, 'sequencer-processor');
                    sequencerNode.port.onmessage = e => e.data.type === 'tick' && handleTick(e.data.step);
                    sequencerNode.connect(audioContext.destination);
                }
            }
            
            function handleTick(step) {
                if (arrangement.length === 0) { if (isPlaying) togglePlayback(); return; }
                const totalSongSteps = arrangement.length * 32;
                if (!isLooping && step >= totalSongSteps) { if(isPlaying) togglePlayback(); return; }
                const currentStepInLoop = isLooping ? (step % totalSongSteps) : step;
                const arrangementIndex = Math.floor(currentStepInLoop / 32);
                const patternIdToPlay = arrangement[arrangementIndex];
                updatePlayhead(currentStepInLoop, arrangementIndex);
                if (isMetronomeOn && (currentStepInLoop % 8 === 0)) { scheduleMetronomeClick(audioContext.currentTime); }
                if (patternIdToPlay === null) return;
                const patternToPlay = patterns.find(p => p.id === patternIdToPlay);
                if (!patternToPlay) return;
                const stepInPattern = currentStepInLoop % 32;
                patternToPlay.tracks.forEach(track => scheduleNote(track, stepInPattern, audioContext.currentTime));
            }
            
            function findNextStep(track, startStep) {
                for (let i = 1; i < 32; i++) {
                    const nextStepIndex = (startStep + i) % 32;
                    if (track.steps[nextStepIndex].active) { return { index: nextStepIndex, stepsAway: i }; }
                }
                return null;
            }

            function scheduleNote(track, stepInPattern, time) {
                const stepData = track.steps[stepInPattern];
                if (!track.audioBuffer || !stepData.active) return;
                
                let releaseDuration = 0.01;
                const nextStepInfo = findNextStep(track, stepInPattern);
                if (nextStepInfo) {
                    releaseDuration = (nextStepInfo.stepsAway * ((60 / tempo) / 8)) * 0.98;
                }

                if (track.playingNode) {
                    track.playingNode.gain.cancelScheduledValues(time);
                    track.playingNode.gain.setValueAtTime(track.playingNode.gain.value, time);
                    track.playingNode.gain.exponentialRampToValueAtTime(0.0001, time + releaseDuration);
                }
                
                let scheduledTime = time;
                if (track.swing > 50 && (stepInPattern % 8 !== 0 && stepInPattern % 4 === 0)) {
                    scheduledTime += (((60 / tempo) / 2) / 3) * ((track.swing - 50) / 25);
                }

                const source = audioContext.createBufferSource();
                source.buffer = track.audioBuffer;
                const panner = audioContext.createStereoPanner();
                panner.pan.setValueAtTime((track.balanceFactor * 2) - 1, scheduledTime);
                const gainNode = audioContext.createGain();
                const finalDb = gainToDbLut[Math.round(stepData.gain)] - track.normalizationGainDb;
                gainNode.gain.setValueAtTime(Math.pow(10, finalDb / 20), scheduledTime);
                source.playbackRate.setValueAtTime(Math.pow(2, (stepData.pitch - 50) / 50), scheduledTime);
                source.connect(panner).connect(gainNode).connect(audioContext.destination);
                source.start(scheduledTime);
                track.playingNode = gainNode;
            }

            function scheduleMetronomeClick(time) {
                const osc = audioContext.createOscillator();
                const gain = audioContext.createGain();
                osc.frequency.setValueAtTime(1000, time);
                gain.gain.setValueAtTime(1, time);
                gain.gain.exponentialRampToValueAtTime(0.001, time + 0.05);
                osc.connect(gain).connect(audioContext.destination);
                osc.start(time);
                osc.stop(time + 0.05);
            }

            function renderAll() {
                renderPatternList();
                renderArrangement();
                renderTracksForCurrentPattern();
            }
            
            function updatePlayhead(currentStepInLoop, currentArrangementIndex) {
                 requestAnimationFrame(() => {
                     document.querySelectorAll('.arranger-step.playing, .step-button.playing').forEach(el => el.classList.remove('playing'));
                     if (currentArrangementIndex < arrangement.length) {
                         const arrangerStepEl = document.querySelectorAll('.arranger-step')[currentArrangementIndex];
                         if(arrangerStepEl) arrangerStepEl.classList.add('playing');
                     }
                      const patternToPlay = patterns.find(p => p.id === arrangement[currentArrangementIndex]);
                      if (!patternToPlay) return;
                      const stepInPattern = currentStepInLoop % 32;
                      patternToPlay.tracks.forEach(track => {
                          if (!track.element) return;
                          const divisionFactor = 32 / track.division;
                          if ((stepInPattern % divisionFactor) === 0) {
                              const stepBtn = track.element.querySelectorAll('.step-button')[Math.floor(stepInPattern / divisionFactor)];
                              if (stepBtn) stepBtn.classList.add('playing');
                          }
                      });
                 });
            }

            function renderPatternList() {
                dom.patternList.innerHTML = '';
                patterns.forEach(pattern => {
                    const btn = document.createElement('button');
                    btn.textContent = pattern.name;
                    btn.className = 'pattern-btn btn btn-secondary px-3 py-1 text-xs';
                    if (pattern.id === currentPatternId) btn.classList.add('selected');
                    btn.onclick = () => switchPattern(pattern.id);
                    dom.patternList.appendChild(btn);
                });
            }

            function renderArrangement() {
                dom.arrangementContainer.innerHTML = '';
                arrangement.forEach((patternId, index) => {
                    const stepEl = document.createElement('button');
                    stepEl.className = 'arranger-step';
                    const pattern = patterns.find(p => p.id === patternId);
                    if (pattern) { stepEl.textContent = pattern.name; }
                    stepEl.onclick = () => {
                        if (patterns.length === 0) return;
                        const currentIndex = patternId === null ? -1 : patterns.findIndex(p => p.id === patternId);
                        const nextIndex = (currentIndex + 1);
                        arrangement[index] = (nextIndex >= patterns.length) ? null : patterns[nextIndex].id;
                        renderArrangement();
                    };
                    dom.arrangementContainer.appendChild(stepEl);
                });
                const addBtn = document.createElement('button');
                addBtn.className = 'add-arrangement-btn btn btn-ghost';
                addBtn.textContent = '+';
                addBtn.onclick = () => { arrangement.push(null); renderArrangement(); };
                dom.arrangementContainer.appendChild(addBtn);
            }
            
            function renderTracksForCurrentPattern() {
                dom.sequencerTracks.innerHTML = '';
                const currentPattern = patterns.find(p => p.id === currentPatternId);
                if (!currentPattern) return;
                currentPattern.tracks.forEach(track => {
                    const trackElement = dom.trackTemplate.content.cloneNode(true).firstElementChild;
                    track.element = trackElement;
                    dom.sequencerTracks.appendChild(trackElement);
                    setupTrackUI(track);
                });
            }

            function setupTrackUI(track) {
                const stepsContainer = track.element.querySelector('.steps-container');
                stepsContainer.innerHTML = '';
                for (let i = 0; i < track.division; i++) {
                    const stepDataIndex = i * (32 / track.division);
                    const stepBtn = document.createElement('button');
                    const stepData = track.steps[stepDataIndex];
                    stepBtn.className = 'step-button';

                    if (i > 0 && i % 4 === 0) {
                        stepBtn.classList.add('mt-2');
                    }

                    if (i % (track.division / 4) === 0) stepBtn.classList.add('beat-marker');
                    if (stepData.active) stepBtn.classList.add('active');
                    
                    const gainIndicator = document.createElement('div');
                    gainIndicator.className = 'indicator gain-indicator';
                    const pitchIndicator = document.createElement('div');
                    pitchIndicator.className = 'indicator pitch-indicator';
                    const updateIndicators = () => {
                        gainIndicator.style.height = `${stepData.gain}%`;
                        pitchIndicator.style.height = `${stepData.pitch}%`;
                    };
                    stepBtn.append(gainIndicator, pitchIndicator);
                    updateIndicators();

                    stepBtn.addEventListener('mousedown', e => {
                        if (e.button !== 0) return;
                        let isDragging = false;
                        const initialY = e.clientY;
                        const rect = e.target.getBoundingClientRect();
                        const dragTarget = (e.clientX - rect.left < rect.width / 2) ? 'gain' : 'pitch';
                        const initialValue = track.steps[stepDataIndex][dragTarget];
                        const onMouseMove = moveEvent => {
                            const deltaY = initialY - moveEvent.clientY;
                            if (!isDragging && Math.abs(deltaY) > 4) isDragging = true;
                            if (isDragging) {
                                track.steps[stepDataIndex][dragTarget] = Math.max(0, Math.min(100, initialValue + deltaY * 0.5));
                                updateIndicators();
                            }
                        };
                        const onMouseUp = () => {
                            window.removeEventListener('mousemove', onMouseMove);
                            window.removeEventListener('mouseup', onMouseUp);
                            if (!isDragging) {
                                track.steps[stepDataIndex].active = !track.steps[stepDataIndex].active;
                                stepBtn.classList.toggle('active');
                            }
                        };
                        window.addEventListener('mousemove', onMouseMove);
                        window.addEventListener('mouseup', onMouseUp);
                    });
                    stepBtn.addEventListener('dblclick', e => {
                        e.preventDefault();
                        const rect = e.target.getBoundingClientRect();
                        if (e.clientX - rect.left < rect.width / 2) track.steps[stepDataIndex].gain = 100;
                        else track.steps[stepDataIndex].pitch = 50;
                        updateIndicators();
                    });
                    stepsContainer.appendChild(stepBtn);
                }
                const loadBtn = track.element.querySelector('.load-sound-btn');
                if (track.audioBuffer) { loadBtn.textContent = track.fileName || 'Loaded Sample'; }
                const fileInput = track.element.querySelector('.file-input');
                loadBtn.onclick = () => fileInput.click();
                fileInput.onchange = async e => {
                    const file = e.target.files[0];
                    if (!file) return;
                    loadBtn.textContent = 'Loading...';
                    await initAudio();
                    track.audioBuffer = await audioContext.decodeAudioData(await file.arrayBuffer());
                    track.fileName = file.name;
                    track.normalizationGainDb = 0;
                    track.balanceFactor = 0.5;
                    track.originalOpusBlob = null;
                    track.packetSizes = null;
                    loadBtn.textContent = file.name;
                };
                const divisionSelect = track.element.querySelector('.division-select');
                divisionSelect.value = track.division;
                divisionSelect.onchange = e => {
                    track.division = parseInt(e.target.value);
                    renderTracksForCurrentPattern();
                };
                const swingSlider = track.element.querySelector('.swing-slider');
                const swingValue = track.element.querySelector('.swing-value');
                swingSlider.value = track.swing;
                swingValue.textContent = `${track.swing}%`;
                swingSlider.oninput = e => {
                    track.swing = parseInt(e.target.value);
                    swingValue.textContent = `${track.swing}%`;
                };
                track.element.querySelector('.remove-track-btn').onclick = () => removeTrack(track.id);
            }

            function addPattern(duplicate = false) {
                const newPatternId = patternIdCounter++;
                let newTracksData = [];
                if (duplicate && currentPatternId !== null) {
                    const sourcePattern = patterns.find(p => p.id === currentPatternId);
                    if (sourcePattern) {
                        newTracksData = sourcePattern.tracks.map((t, i) => ({ ...t, id: `${newPatternId}-${i}`, element: null, steps: JSON.parse(JSON.stringify(t.steps)), playingNode: null }));
                    }
                }
                patterns.push({ id: newPatternId, name: `P${newPatternId + 1}`, tracks: newTracksData });
                if (patterns.length === 1 && arrangement.length === 0) arrangement.push(newPatternId);
                switchPattern(newPatternId);
                renderArrangement();
            }

            function switchPattern(patternId) {
                currentPatternId = patternId;
                renderTracksForCurrentPattern();
                renderPatternList();
            }

            function addTrack() {
                const currentPattern = patterns.find(p => p.id === currentPatternId);
                if (!currentPattern) return;
                const trackId = `${currentPatternId}-${currentPattern.tracks.length}`;
                const newTrack = { id: trackId, division: 16, swing: 50, normalizationGainDb: 0, balanceFactor: 0.5, steps: Array(32).fill(null).map(() => ({ active: false, pitch: 50, gain: 100 })), originalOpusBlob: null, packetSizes: null };
                currentPattern.tracks.push(newTrack);
                renderTracksForCurrentPattern();
            }

            function removeTrack(trackId) {
                const currentPattern = patterns.find(p => p.id === currentPatternId);
                if (!currentPattern) return;
                const trackIndex = currentPattern.tracks.findIndex(t => t.id === trackId);
                if (trackIndex > -1) {
                    currentPattern.tracks.splice(trackIndex, 1);
                    renderTracksForCurrentPattern();
                }
            }
            
            async function togglePlayback() {
                isPlaying = !isPlaying;
                if(isPlaying){
                    await initAudio();
                    sequencerNode.port.postMessage({ type: 'setTempo', value: tempo });
                    sequencerNode.port.postMessage({ type: 'start' });
                    dom.playStopBtn.textContent = 'Stop';
                    dom.playStopBtn.classList.remove('btn-primary');
                    dom.playStopBtn.style.backgroundColor = 'var(--accent-cyan)';
                    dom.playStopBtn.style.color = 'var(--bg-main)';
                } else {
                    sequencerNode.port.postMessage({ type: 'stop' });
                    patterns.forEach(p => p.tracks.forEach(t => t.playingNode = null));
                    dom.playStopBtn.textContent = 'Play';
                    dom.playStopBtn.classList.add('btn-primary');
                    dom.playStopBtn.style.backgroundColor = '';
                    dom.playStopBtn.style.color = '';
                    document.querySelectorAll('.playing').forEach(el => el.classList.remove('playing'));
                }
            }
            
            async function resampleBuffer(audioBuffer, targetSampleRate) {
                const offlineContext = new OfflineAudioContext(
                    audioBuffer.numberOfChannels,
                    Math.ceil(audioBuffer.duration * targetSampleRate),
                    targetSampleRate
                );
                const bufferSource = offlineContext.createBufferSource();
                bufferSource.buffer = audioBuffer;
                bufferSource.connect(offlineContext.destination);
                bufferSource.start(0);
                return await offlineContext.startRendering();
            }
            
            // --- NEW: DSP Filter Functions ---
            function applyPreEmphasis(data, alpha = 0.97) {
                const filteredData = new Float32Array(data.length);
                filteredData[0] = data[0];
                for (let i = 1; i < data.length; i++) {
                    filteredData[i] = data[i] - alpha * data[i - 1];
                }
                return filteredData;
            }

            function applyDeEmphasis(data, alpha = 0.97) {
                const filteredData = new Float32Array(data.length);
                filteredData[0] = data[0];
                for (let i = 1; i < data.length; i++) {
                    filteredData[i] = data[i] + alpha * filteredData[i - 1];
                }
                return filteredData;
            }

            // --- NEW: Cross-correlation for phase alignment ---
            function crossCorrelate(ch1, ch2) {
                const len = ch1.length;
                let maxCorr = 0;
                let bestLag = 0;
                // Search a limited lag range for efficiency
                const searchRange = Math.min(len, Math.floor(audioContext.sampleRate * 0.002)); // 2ms search window

                for (let lag = -searchRange; lag <= searchRange; lag++) {
                    let corr = 0;
                    for (let i = 0; i < len; i++) {
                        const ch2Index = i + lag;
                        if (ch2Index >= 0 && ch2Index < len) {
                            corr += ch1[i] * ch2[ch2Index];
                        }
                    }
                    if (Math.abs(corr) > Math.abs(maxCorr)) {
                        maxCorr = corr;
                        bestLag = lag;
                    }
                }
                return bestLag;
            }


            async function processAudioForSaving(buffer) {
                console.log(`[SAVE] Starting audio processing for buffer with ${buffer.numberOfChannels} channels and sample rate: ${buffer.sampleRate} Hz.`);
                
                let monoBuffer;
                let balanceFactor = 0.5;

                if (buffer.numberOfChannels > 1) {
                    console.log('[SAVE] Analyzing stereo energy and phase.');
                    let leftChannel = buffer.getChannelData(0);
                    let rightChannel = buffer.getChannelData(1);
                    
                    // --- PHASE ALIGNMENT via CROSS-CORRELATION ---
                    const lag = crossCorrelate(leftChannel, rightChannel);
                    if (lag !== 0) {
                        console.log(`[SAVE] Applying phase correction lag of ${lag} samples.`);
                        const newLeft = new Float32Array(leftChannel.length);
                        const newRight = new Float32Array(rightChannel.length);
                        if (lag > 0) { // right leads left, shift right forward
                           rightChannel.copyWithin(0, lag);
                        } else { // left leads right, shift left forward
                           leftChannel.copyWithin(0, -lag);
                        }
                    }

                    // --- Energy analysis for balance factor ---
                    let sumSquaresL = 0.0, sumSquaresR = 0.0;
                    for (let i = 0; i < leftChannel.length; i++) {
                        sumSquaresL += leftChannel[i] * leftChannel[i];
                        sumSquaresR += rightChannel[i] * rightChannel[i];
                    }
                    const rmsL = Math.sqrt(sumSquaresL / leftChannel.length);
                    const rmsR = Math.sqrt(sumSquaresR / rightChannel.length);
                    const totalRms = rmsL + rmsR;
                    if (totalRms > 1e-5) balanceFactor = rmsR / totalRms;
                    console.log(`[SAVE] RMS L: ${rmsL.toFixed(3)}, RMS R: ${rmsR.toFixed(3)}. Balance factor: ${balanceFactor.toFixed(3)}`);

                    // --- Phase-corrected mono sum ---
                    const monoData = new Float32Array(leftChannel.length);
                    for (let i = 0; i < leftChannel.length; i++) {
                        monoData[i] = (leftChannel[i] + rightChannel[i]) / 2.0;
                    }
                    monoBuffer = audioContext.createBuffer(1, monoData.length, buffer.sampleRate);
                    monoBuffer.copyToChannel(monoData, 0);

                } else {
                    monoBuffer = buffer;
                }

                // --- RESAMPLING ---
                let processedBuffer = monoBuffer;
                if (processedBuffer.sampleRate !== TARGET_SAMPLE_RATE) {
                    console.log(`[SAVE] Resampling from ${processedBuffer.sampleRate} Hz to ${TARGET_SAMPLE_RATE} Hz.`);
                    processedBuffer = await resampleBuffer(processedBuffer, TARGET_SAMPLE_RATE);
                }

                // --- SILENCE TRIMMING ---
                const channelData = processedBuffer.getChannelData(0);
                let first = 0, last = channelData.length - 1;
                while (first < last && Math.abs(channelData[first]) < 1e-4) first++;
                while (last > first && Math.abs(channelData[last]) < 1e-4) last--;
                if (first >= last) return { buffer: audioContext.createBuffer(1, 1, TARGET_SAMPLE_RATE), normalizationGainDb: 0, balanceFactor: 0.5 };
                const trimmedData = channelData.slice(first, last + 1);
                
                // --- DYNAMIC-PRESERVING NORMALIZATION ---
                const TARGET_PEAK = 0.97; // -0.3 dBFS
                const TARGET_RMS = 0.5;
                let currentPeak = 0, sumSquares = 0.0;
                for (let i = 0; i < trimmedData.length; i++) {
                    const sample = trimmedData[i];
                    sumSquares += sample * sample;
                    if (Math.abs(sample) > currentPeak) currentPeak = Math.abs(sample);
                }
                const currentRms = Math.sqrt(sumSquares / trimmedData.length);
                
                let gainToApply = 1.0;
                let normDb = 0;

                if (currentRms > 1e-5) {
                    const gainForPeak = (currentPeak > 1e-5) ? TARGET_PEAK / currentPeak : Infinity;
                    const gainForRms = TARGET_RMS / currentRms;
                    gainToApply = Math.min(gainForPeak, gainForRms);
                    normDb = 20 * Math.log10(gainToApply);

                    for (let i = 0; i < trimmedData.length; i++) {
                        trimmedData[i] *= gainToApply;
                    }
                }
                 console.log(`[SAVE] Normalization complete. Peak: ${currentPeak.toFixed(3)}, RMS: ${currentRms.toFixed(3)}. Applied gain: ${normDb.toFixed(2)} dB.`);
                
                // --- PRE-EMPHASIS ---
                console.log('[SAVE] Applying pre-emphasis filter...');
                const emphasizedData = applyPreEmphasis(trimmedData);

                const finalBuffer = audioContext.createBuffer(1, emphasizedData.length, TARGET_SAMPLE_RATE);
                finalBuffer.copyToChannel(emphasizedData, 0);
                
                return { buffer: finalBuffer, normalizationGainDb: normDb, balanceFactor: balanceFactor };
            }

            function serializeState(audioAssets, audioBufferMap) {
                const textEncoder = new TextEncoder();
                let totalSize = 5 + arrangement.length;
                patterns.forEach(p => {
                    totalSize += 3 + textEncoder.encode(p.name).length;
                    totalSize += p.tracks.length * (3 + 96);
                });
                audioAssets.forEach(asset => {
                    totalSize += 9; 
                    totalSize += 2; 
                    totalSize += asset.packetSizes.length * 2;
                });

                const buffer = new ArrayBuffer(totalSize);
                const view = new DataView(buffer);
                let offset = 0;
                view.setUint16(offset, tempo); offset += 2;
                view.setUint8(offset, arrangement.length); offset += 1;
                view.setUint8(offset, patterns.length); offset += 1;
                view.setUint8(offset, audioAssets.length); offset += 1;
                arrangement.forEach(pId => { view.setUint8(offset, pId === null ? 255 : pId); offset += 1; });
                
                audioAssets.forEach(asset => {
                    view.setUint32(offset, asset.buffer.sampleRate); offset += 4;
                    view.setFloat32(offset, asset.normalizationGainDb); offset += 4;
                    view.setUint8(offset, Math.round(asset.balanceFactor * 255)); offset += 1;
                    view.setUint16(offset, asset.packetSizes.length); offset += 2;
                    asset.packetSizes.forEach(size => {
                        view.setUint16(offset, size); offset += 2;
                    });
                });

                patterns.forEach(p => {
                    const nameBytes = textEncoder.encode(p.name);
                    view.setUint8(offset, p.id); offset += 1;
                    view.setUint8(offset, p.tracks.length); offset += 1;
                    view.setUint8(offset, nameBytes.length); offset += 1;
                    nameBytes.forEach(b => { view.setUint8(offset, b); offset++; });
                    p.tracks.forEach(t => {
                        view.setUint8(offset, t.audioBuffer ? audioBufferMap.get(t.audioBuffer) : 255); offset++;
                        view.setUint8(offset, t.division); offset++;
                        view.setUint8(offset, t.swing); offset++;
                        t.steps.forEach(s => {
                            view.setUint8(offset, s.active ? 1 : 0); offset++;
                            view.setUint8(offset, Math.round(s.pitch)); offset++;
                            view.setUint8(offset, Math.round(s.gain)); offset++;
                        });
                    });
                });
                console.log(`[SAVE] State serialization complete. Total size: ${offset} bytes.`);
                return new Blob([buffer]);
            }
            
            async function parseState(buffer, audioFileMap) {
                console.log(`[LOAD] Beginning state parsing.`);
                const view = new DataView(buffer);
                let offset = 0;
                tempo = view.getUint16(offset); offset += 2;
                dom.tempoSlider.value = tempo; dom.tempoValue.textContent = tempo;
                if (sequencerNode) sequencerNode.port.postMessage({ type: 'setTempo', value: tempo });

                const arrLen = view.getUint8(offset++);
                const patLen = view.getUint8(offset++);
                const audLen = view.getUint8(offset++);
                console.log(`[LOAD] Project metadata: ${arrLen} arrangement steps, ${patLen} patterns, ${audLen} audio assets.`);
                
                arrangement = Array.from({ length: arrLen }, () => {
                    const id = view.getUint8(offset++);
                    return id === 255 ? null : id;
                });

                const audioAssets = [];
                for (let i = 0; i < audLen; i++) {
                    const sampleRate = view.getUint32(offset); offset += 4;
                    const normDb = view.getFloat32(offset); offset += 4;
                    const bal = view.getUint8(offset++) / 255.0;
                    
                    const packetCount = view.getUint16(offset); offset += 2;
                    const packetSizes = [];
                    for(let j = 0; j < packetCount; j++) {
                        packetSizes.push(view.getUint16(offset)); offset += 2;
                    }

                    const audioFile = audioFileMap.get(i);
                    let pcmData;
                    
                    console.log(`[LOAD] Processing audio asset #${i} with stored sample rate ${sampleRate} Hz.`);

                    if (audioFile && audioFile.name.endsWith('.opus')) {
                        console.log(`[LOAD]   Type is Opus. Decoding with ${packetSizes.length} packets...`);
                        pcmData = await opusDecoder.decode(audioFile.blob, sampleRate, packetSizes);

                        if (pcmData && pcmData.length > 0) {
                            console.log('[LOAD]   Applying de-emphasis filter...');
                            pcmData = applyDeEmphasis(pcmData);
                        }
                    } 
                    if (pcmData && pcmData.length > 0) {
                        const audioBuffer = audioContext.createBuffer(1, pcmData.length, sampleRate);
                        audioBuffer.copyToChannel(pcmData, 0);
                        audioAssets.push({ buffer: audioBuffer, normDb, bal, blob: audioFile.blob, packetSizes });
                        console.log(`[LOAD]   Asset #${i} successfully loaded into AudioBuffer.`);
                    } else {
                         console.error(`[LOAD]   Failed to load or decode asset #${i}.`);
                    }
                }
                
                const textDecoder = new TextDecoder();
                patterns = [];
                let maxId = -1;
                for (let i = 0; i < patLen; i++) {
                    const id = view.getUint8(offset++); maxId = Math.max(maxId, id);
                    const trackCount = view.getUint8(offset++);
                    const nameLen = view.getUint8(offset++);
                    const name = textDecoder.decode(new Uint8Array(buffer, offset, nameLen)); offset += nameLen;
                    const newPattern = { id, name, tracks: [] };
                    for (let j = 0; j < trackCount; j++) {
                        const audioIndex = view.getUint8(offset++);
                        const asset = audioAssets[audioIndex];
                        const newTrack = {
                            id: `${id}-${j}`,
                            audioBuffer: !asset ? null : asset.buffer,
                            originalOpusBlob: !asset ? null : asset.blob,
                            packetSizes: !asset ? null : asset.packetSizes,
                            fileName: !asset ? null : `audio_${audioIndex}`,
                            normalizationGainDb: !asset ? 0 : asset.normDb,
                            balanceFactor: !asset ? 0.5 : asset.bal,
                            division: view.getUint8(offset++),
                            swing: view.getUint8(offset++),
                            steps: Array.from({ length: 32 }, () => ({
                                active: view.getUint8(offset++) === 1,
                                pitch: view.getUint8(offset++),
                                gain: view.getUint8(offset++),
                            }))
                        };
                        newPattern.tracks.push(newTrack);
                    }
                    patterns.push(newPattern);
                }
                patternIdCounter = maxId + 1;
                currentPatternId = patterns[0]?.id ?? null;
                console.log(`[LOAD] State parsing complete.`);
            }
            
            async function saveProject() {
                setButtonLoading(dom.saveProjectBtn, true);
                try {
                    console.log(`[SAVE] Starting project save...`);
                    await initAudio();
                    const zip = new JSZip();
                    const audioAssets = [];
                    const audioBufferMap = new Map();
                    const tracksWithAudio = patterns.flatMap(p => p.tracks).filter(t => t.audioBuffer);

                    for (const track of tracksWithAudio) {
                        if (audioBufferMap.has(track.audioBuffer)) continue;

                        const assetIndex = audioAssets.length;
                        audioBufferMap.set(track.audioBuffer, assetIndex);
                        
                        if (track.originalOpusBlob && track.originalOpusBlob.type === 'audio/opus' && track.packetSizes) {
                            console.log(`[SAVE] Asset #${assetIndex} is already optimized. Re-using existing blob.`);
                             audioAssets.push({
                                 buffer: track.audioBuffer,
                                 normalizationGainDb: track.normalizationGainDb,
                                 balanceFactor: track.balanceFactor,
                                 packetSizes: track.packetSizes,
                                 blob: track.originalOpusBlob,
                                 extension: 'opus'
                             });
                        } else {
                            console.log(`[SAVE] Asset #${assetIndex} is new or legacy. Processing...`);
                            const processedAsset = await processAudioForSaving(track.audioBuffer);
                            const encodeResult = await opusEncoder.encode(processedAsset.buffer, { bitrate: 32000 });
                            audioAssets.push({
                                ...processedAsset,
                                packetSizes: encodeResult.packetSizes,
                                blob: encodeResult.blob,
                                extension: 'opus'
                            });
                        }
                    }

                    audioAssets.forEach((asset, i) => {
                         console.log(`[SAVE] Adding asset #${i} as ${asset.extension} with size ${asset.blob.size} bytes.`);
                         zip.file(`audio_${i}.${asset.extension}`, asset.blob);
                    });

                    zip.file('project.bin', serializeState(audioAssets, audioBufferMap));

                    const content = await zip.generateAsync({ type: 'blob', compression: "DEFLATE", compressionOptions: { level: 9 } });
                    const a = document.createElement('a');
                    a.href = URL.createObjectURL(content);
                    a.download = `project.wmus`;
                    a.click();
                    a.remove();
                    URL.revokeObjectURL(a.href);
                    console.log(`[SAVE] Project save complete. Total size: ${content.size} bytes.`);
                } catch (error) {
                    console.error("Failed to save project:", error);
                    // NOTE: The original code used alert(), which is blocked in this environment.
                    // A proper implementation would use a custom modal for user feedback.
                } finally {
                    setButtonLoading(dom.saveProjectBtn, false);
                }
            }
            
            async function loadProject(file) {
                 if (!file) return;
                 setButtonLoading(dom.loadProjectBtn, true);
                 try {
                     console.log(`[LOAD] Loading project file: ${file.name}`);
                     await initAudio();
                     const zip = await JSZip.loadAsync(file);
                     const projectFile = zip.file('project.bin');
                     if (!projectFile) throw new Error('Invalid project file: project.bin not found.');
                     
                     const projectBuffer = await projectFile.async('arraybuffer');
                     
                     const audioFileMap = new Map();
                     const audioFilePromises = Object.values(zip.files)
                         .filter(f => f.name.startsWith('audio_') && f.name.endsWith('.opus'))
                         .map(async (f) => {
                             const index = parseInt(f.name.match(/(\d+)/)[0]);
                             const blob = await f.async('blob');
                             console.log(`[LOAD] Found audio file in zip: ${f.name} (index ${index})`);
                             audioFileMap.set(index, { blob, name: f.name });
                         });

                     await Promise.all(audioFilePromises);
                     
                     await parseState(projectBuffer, audioFileMap);
                     renderAll();
                     console.log(`[LOAD] Project loaded successfully.`);
                 } catch (error) {
                     console.error("Failed to load project:", error);
                 } finally {
                     setButtonLoading(dom.loadProjectBtn, false);
                     dom.loadProjectInput.value = '';
                 }
            }
            
            function setButtonLoading(button, isLoading) {
                const originalText = button.dataset.originalText || button.textContent;
                if (!button.dataset.originalText) button.dataset.originalText = originalText;
                if (isLoading) {
                    button.disabled = true;
                    button.innerHTML = `<div class="spinner mr-2"></div><span>Loading...</span>`;
                } else {
                    button.disabled = false;
                    button.innerHTML = originalText;
                }
            }

            // --- EVENT LISTENERS & INITIALIZATION ---
            dom.playStopBtn.addEventListener('click', togglePlayback);
            dom.loopToggleBtn.addEventListener('click', () => { isLooping = !isLooping; dom.loopToggleBtn.classList.toggle('active', isLooping); });
            dom.metronomeToggleBtn.addEventListener('click', () => { isMetronomeOn = !isMetronomeOn; dom.metronomeToggleBtn.classList.toggle('active', isMetronomeOn); });
            dom.tempoSlider.addEventListener('input', e => { tempo = parseInt(e.target.value); dom.tempoValue.textContent = tempo; if (sequencerNode) sequencerNode.port.postMessage({ type: 'setTempo', value: tempo }); });
            dom.addTrackBtn.addEventListener('click', addTrack);
            dom.addPatternBtn.addEventListener('click', () => addPattern(false));
            dom.dupPatternBtn.addEventListener('click', () => addPattern(true));
            dom.saveProjectBtn.addEventListener('click', saveProject);
            dom.loadProjectBtn.addEventListener('click', () => dom.loadProjectInput.click());
            dom.loadProjectInput.addEventListener('change', (e) => loadProject(e.target.files[0]));

            addPattern();
        });
    </script>
</body>
</html>

